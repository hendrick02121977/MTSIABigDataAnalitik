{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Praktikum Minggu 15: Studi Kasus End-to-End — Prediksi Churn Pelanggan\n",
    "## *Week 15 Lab: End-to-End Case Study — Customer Churn Prediction*\n",
    "\n",
    "**Mata Kuliah / Course:** Big Data Analytics  \n",
    "**Topik / Topic:** CRISP-DM, EDA, Feature Engineering, ML Pipeline, Deployment  \n",
    "\n",
    "---\n",
    "### Deskripsi\n",
    "Praktikum ini menerapkan metodologi CRISP-DM secara end-to-end untuk memprediksi\n",
    "churn pelanggan telekomunikasi — salah satu use case paling umum di industri.\n",
    "Kita akan melalui seluruh siklus proyek data analytics dari business understanding\n",
    "hingga simulasi deployment."
   ],
   "id": "cell-md-title"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score,\n",
    "    roc_curve, precision_recall_curve\n",
    ")\n",
    "import joblib\n",
    "\n",
    "np.random.seed(42)\n",
    "print('Libraries loaded successfully!')"
   ],
   "id": "cell-imports"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Studi Kasus: Prediksi Churn Pelanggan Telekomunikasi\n",
    "\n",
    "**Churn** (customer attrition) adalah ketika pelanggan berhenti menggunakan layanan.\n",
    "Biaya akuisisi pelanggan baru 5–25× lebih mahal daripada mempertahankan pelanggan lama.\n",
    "Mengidentifikasi pelanggan berisiko churn lebih awal sangat bernilai bagi bisnis."
   ],
   "id": "cell-md-case-study"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate realistic telecom churn dataset (1000 customers)\n",
    "def generate_telecom_dataset(n=1000, seed=42):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Features\n",
    "    tenure = np.random.exponential(scale=24, size=n).astype(int).clip(1, 72)\n",
    "    contract_type = np.random.choice(['Month-to-Month', 'One Year', 'Two Year'],\n",
    "                                      size=n, p=[0.55, 0.25, 0.20])\n",
    "    payment_method = np.random.choice(\n",
    "        ['Electronic Check', 'Mailed Check', 'Bank Transfer', 'Credit Card'],\n",
    "        size=n, p=[0.35, 0.25, 0.22, 0.18]\n",
    "    )\n",
    "    num_services   = np.random.randint(1, 7, size=n)\n",
    "    monthly_charges = 20 + num_services * 8 + np.random.normal(0, 5, n)\n",
    "    monthly_charges = monthly_charges.clip(18, 120).round(2)\n",
    "    total_charges   = (tenure * monthly_charges + np.random.normal(0, 20, n)).clip(0).round(2)\n",
    "    cust_service_calls = np.random.poisson(1.5, n).clip(0, 10)\n",
    "\n",
    "    # Churn probability (business logic)\n",
    "    churn_score = (\n",
    "        0.40 * (contract_type == 'Month-to-Month').astype(int)\n",
    "        - 0.20 * (tenure > 24).astype(int)\n",
    "        + 0.15 * (cust_service_calls > 3).astype(int)\n",
    "        + 0.10 * (payment_method == 'Electronic Check').astype(int)\n",
    "        - 0.10 * (num_services > 4).astype(int)\n",
    "        + np.random.normal(0, 0.15, n)\n",
    "    )\n",
    "    churn_prob = 1 / (1 + np.exp(-churn_score * 2))\n",
    "    churn = (churn_prob > 0.5).astype(int)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'customer_id': [f'CUST_{i:04d}' for i in range(1, n+1)],\n",
    "        'tenure': tenure,\n",
    "        'contract_type': contract_type,\n",
    "        'payment_method': payment_method,\n",
    "        'num_services': num_services,\n",
    "        'monthly_charges': monthly_charges,\n",
    "        'total_charges': total_charges,\n",
    "        'customer_service_calls': cust_service_calls,\n",
    "        'churn': churn\n",
    "    })\n",
    "\n",
    "df = generate_telecom_dataset(n=1000)\n",
    "print(f'Dataset shape: {df.shape}')\n",
    "print(f'Churn rate: {df[\"churn\"].mean():.2%}')\n",
    "print('\\nFirst 5 rows:')\n",
    "print(df.head())\n",
    "print('\\nData types & nulls:')\n",
    "print(df.info())"
   ],
   "id": "cell-generate-data"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Business Understanding (CRISP-DM)\n",
    "\n",
    "Mendefinisikan masalah bisnis secara jelas sebelum mulai menganalisis data."
   ],
   "id": "cell-md-1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_problem = \"\"\"\n",
    "╔══════════════════════════════════════════════════════════════════════════╗\n",
    "║                 BUSINESS UNDERSTANDING — CRISP-DM PHASE 1               ║\n",
    "╠══════════════════════════════════════════════════════════════════════════╣\n",
    "║                                                                          ║\n",
    "║  MASALAH BISNIS:                                                         ║\n",
    "║  TelcoIndo mengalami churn rate 26% per kuartal. Setiap pelanggan        ║\n",
    "║  yang churn merepresentasikan kerugian rata-rata Rp 2.4 juta/tahun.     ║\n",
    "║  Dengan 50.000 pelanggan aktif, churn 26% = 13.000 pelanggan hilang      ║\n",
    "║  = kerugian Rp 31.2 miliar/tahun.                                        ║\n",
    "║                                                                          ║\n",
    "║  TUJUAN ANALITIK:                                                        ║\n",
    "║  Membangun model prediksi churn dengan recall ≥ 70% untuk                ║\n",
    "║  mengidentifikasi pelanggan berisiko tinggi 30 hari sebelum churn.       ║\n",
    "║                                                                          ║\n",
    "║  STRATEGI INTERVENSI:                                                    ║\n",
    "║  - High-risk (score > 0.7): Proactive outreach + retention offer         ║\n",
    "║  - Medium-risk (0.4-0.7): Loyalty reward program                         ║\n",
    "║  - Low-risk (< 0.4): Standard retention program                          ║\n",
    "║                                                                          ║\n",
    "║  SUCCESS CRITERIA:                                                       ║\n",
    "║  - Model recall ≥ 70% (minimize false negatives)                         ║\n",
    "║  - ROC-AUC ≥ 0.75                                                        ║\n",
    "║  - Reduce churn by 15% within 6 months post-deployment                   ║\n",
    "╚══════════════════════════════════════════════════════════════════════════╝\n",
    "\"\"\"\n",
    "print(business_problem)"
   ],
   "id": "cell-business-understanding"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Understanding — EDA\n",
    "\n",
    "Eksplorasi data secara menyeluruh: distribusi, korelasi, dan pola churn."
   ],
   "id": "cell-md-2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== Basic Statistics ===')\n",
    "print(df.describe().round(2))\n",
    "\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "gs = gridspec.GridSpec(3, 3, figure=fig)\n",
    "\n",
    "# 1. Churn distribution\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "churn_counts = df['churn'].value_counts()\n",
    "ax1.pie(churn_counts, labels=['No Churn', 'Churn'], autopct='%1.1f%%',\n",
    "        colors=['steelblue', 'tomato'], startangle=90)\n",
    "ax1.set_title('Churn Distribution')\n",
    "\n",
    "# 2. Tenure distribution by churn\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "df[df['churn']==0]['tenure'].hist(bins=20, ax=ax2, alpha=0.6, color='steelblue', label='No Churn')\n",
    "df[df['churn']==1]['tenure'].hist(bins=20, ax=ax2, alpha=0.6, color='tomato', label='Churn')\n",
    "ax2.set_title('Tenure Distribution by Churn'); ax2.legend()\n",
    "\n",
    "# 3. Monthly charges by churn\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "df.boxplot(column='monthly_charges', by='churn', ax=ax3)\n",
    "ax3.set_title('Monthly Charges by Churn'); ax3.set_xlabel('Churn (0=No, 1=Yes)')\n",
    "plt.sca(ax3)  # suppress automatic figure title\n",
    "\n",
    "# 4. Churn rate by contract type\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "churn_by_contract = df.groupby('contract_type')['churn'].mean().sort_values(ascending=False)\n",
    "churn_by_contract.plot(kind='bar', ax=ax4, color='coral', edgecolor='white')\n",
    "ax4.set_title('Churn Rate by Contract Type'); ax4.set_ylabel('Churn Rate')\n",
    "ax4.tick_params(axis='x', rotation=20)\n",
    "for bar, val in zip(ax4.patches, churn_by_contract):\n",
    "    ax4.text(bar.get_x()+0.2, bar.get_height()+0.01, f'{val:.1%}', fontsize=9)\n",
    "\n",
    "# 5. Churn rate by payment method\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "churn_by_pay = df.groupby('payment_method')['churn'].mean().sort_values(ascending=False)\n",
    "churn_by_pay.plot(kind='bar', ax=ax5, color='mediumpurple', edgecolor='white')\n",
    "ax5.set_title('Churn Rate by Payment Method'); ax5.set_ylabel('Churn Rate')\n",
    "ax5.tick_params(axis='x', rotation=30)\n",
    "\n",
    "# 6. Customer service calls vs churn\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "churn_by_calls = df.groupby('customer_service_calls')['churn'].mean()\n",
    "ax6.bar(churn_by_calls.index, churn_by_calls.values, color='sandybrown')\n",
    "ax6.set_title('Churn Rate by Service Calls'); ax6.set_xlabel('# Service Calls')\n",
    "ax6.set_ylabel('Churn Rate')\n",
    "\n",
    "# 7. Correlation heatmap (numeric only)\n",
    "ax7 = fig.add_subplot(gs[2, :])\n",
    "numeric_cols = ['tenure', 'num_services', 'monthly_charges', 'total_charges',\n",
    "                'customer_service_calls', 'churn']\n",
    "corr_matrix = df[numeric_cols].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', ax=ax7,\n",
    "            square=True, linewidths=0.5)\n",
    "ax7.set_title('Feature Correlation Heatmap')\n",
    "\n",
    "fig.suptitle('Exploratory Data Analysis — Telecom Churn Dataset', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Key findings\n",
    "print('\\n=== Key EDA Findings ===')\n",
    "print(f'- Overall churn rate: {df[\"churn\"].mean():.1%}')\n",
    "print(f'- Month-to-Month churn rate: {df[df[\"contract_type\"]==\"Month-to-Month\"][\"churn\"].mean():.1%}')\n",
    "print(f'- Two Year contract churn rate: {df[df[\"contract_type\"]==\"Two Year\"][\"churn\"].mean():.1%}')\n",
    "print(f'- Avg tenure churners: {df[df[\"churn\"]==1][\"tenure\"].mean():.1f} months')\n",
    "print(f'- Avg tenure non-churners: {df[df[\"churn\"]==0][\"tenure\"].mean():.1f} months')"
   ],
   "id": "cell-eda"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation\n",
    "\n",
    "Preprocessing pipeline: encoding kategoris, scaling numerik, train/test split."
   ],
   "id": "cell-md-3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target\n",
    "feature_cols = ['tenure', 'contract_type', 'payment_method', 'num_services',\n",
    "                'monthly_charges', 'total_charges', 'customer_service_calls']\n",
    "target_col = 'churn'\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df[target_col].copy()\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "numeric_features = ['tenure', 'num_services', 'monthly_charges',\n",
    "                    'total_charges', 'customer_service_calls']\n",
    "categorical_features = ['contract_type', 'payment_method']\n",
    "\n",
    "# Preprocessing pipeline\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# Train/test split (stratified to preserve churn ratio)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f'Train size: {X_train.shape[0]} | Test size: {X_test.shape[0]}')\n",
    "print(f'Train churn rate: {y_train.mean():.2%} | Test churn rate: {y_test.mean():.2%}')\n",
    "\n",
    "# Fit preprocessor\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_test_proc  = preprocessor.transform(X_test)\n",
    "\n",
    "# Get feature names after preprocessing\n",
    "cat_feature_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features)\n",
    "all_feature_names = numeric_features + list(cat_feature_names)\n",
    "print(f'\\nProcessed feature count: {X_train_proc.shape[1]}')\n",
    "print(f'Feature names: {all_feature_names}')"
   ],
   "id": "cell-data-prep"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling — Beberapa Algoritma\n",
    "\n",
    "Melatih dan membandingkan tiga algoritma: Logistic Regression, Random Forest, Gradient Boosting."
   ],
   "id": "cell-md-4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models_dict = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=500, random_state=42, C=1.0),\n",
    "    'Random Forest':       RandomForestClassifier(n_estimators=100, random_state=42, max_depth=8),\n",
    "    'Gradient Boosting':   GradientBoostingClassifier(n_estimators=100, random_state=42, learning_rate=0.1)\n",
    "}\n",
    "\n",
    "# Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_results = {}\n",
    "\n",
    "print('=== Cross-Validation Results (5-fold Stratified) ===')\n",
    "for name, model in models_dict.items():\n",
    "    scores = cross_val_score(model, X_train_proc, y_train, cv=cv,\n",
    "                              scoring='roc_auc', n_jobs=-1)\n",
    "    cv_results[name] = scores\n",
    "    print(f'{name:25s}: AUC = {scores.mean():.4f} ± {scores.std():.4f}')\n",
    "\n",
    "# Train all models on full training set\n",
    "trained_models = {}\n",
    "for name, model in models_dict.items():\n",
    "    model.fit(X_train_proc, y_train)\n",
    "    trained_models[name] = model\n",
    "\n",
    "# Evaluate on test set\n",
    "print('\\n=== Test Set Evaluation ===')\n",
    "results_df_rows = []\n",
    "for name, model in trained_models.items():\n",
    "    y_pred = model.predict(X_test_proc)\n",
    "    y_proba = model.predict_proba(X_test_proc)[:, 1]\n",
    "    results_df_rows.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': round(accuracy_score(y_test, y_pred), 4),\n",
    "        'Precision': round(precision_score(y_test, y_pred), 4),\n",
    "        'Recall': round(recall_score(y_test, y_pred), 4),\n",
    "        'F1-Score': round(f1_score(y_test, y_pred), 4),\n",
    "        'ROC-AUC': round(roc_auc_score(y_test, y_proba), 4)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results_df_rows).set_index('Model')\n",
    "print(results_df.to_string())\n",
    "\n",
    "# Select best model by ROC-AUC\n",
    "best_model_name = results_df['ROC-AUC'].idxmax()\n",
    "best_model = trained_models[best_model_name]\n",
    "print(f'\\n✅ Best model: {best_model_name} (AUC = {results_df.loc[best_model_name, \"ROC-AUC\"]:.4f})')"
   ],
   "id": "cell-modeling"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation\n",
    "\n",
    "Evaluasi mendalam model terbaik: confusion matrix, ROC curve, feature importance."
   ],
   "id": "cell-md-5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_best  = best_model.predict(X_test_proc)\n",
    "y_proba_best = best_model.predict_proba(X_test_proc)[:, 1]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# 1. Confusion Matrix\n",
    "ax = axes[0]\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "            xticklabels=['No Churn', 'Churn'],\n",
    "            yticklabels=['No Churn', 'Churn'])\n",
    "ax.set_title(f'{best_model_name}\\nConfusion Matrix')\n",
    "ax.set_ylabel('Actual'); ax.set_xlabel('Predicted')\n",
    "\n",
    "# 2. ROC Curves (all models)\n",
    "ax = axes[1]\n",
    "colors = ['steelblue', 'tomato', 'seagreen']\n",
    "for (name, model), color in zip(trained_models.items(), colors):\n",
    "    y_proba = model.predict_proba(X_test_proc)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    ax.plot(fpr, tpr, color=color, label=f'{name} (AUC={auc:.3f})')\n",
    "ax.plot([0,1],[0,1], 'k--', alpha=0.5)\n",
    "ax.set_title('ROC Curves — All Models')\n",
    "ax.set_xlabel('False Positive Rate'); ax.set_ylabel('True Positive Rate')\n",
    "ax.legend(fontsize=8); ax.grid(alpha=0.3)\n",
    "\n",
    "# 3. Feature Importance (for tree-based models)\n",
    "ax = axes[2]\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importance = pd.Series(best_model.feature_importances_, index=all_feature_names)\n",
    "    importance.sort_values(ascending=True).tail(10).plot(kind='barh', ax=ax, color='steelblue')\n",
    "    ax.set_title(f'{best_model_name}\\nTop Feature Importances')\n",
    "    ax.set_xlabel('Importance')\n",
    "elif hasattr(best_model, 'coef_'):\n",
    "    coef = pd.Series(np.abs(best_model.coef_[0]), index=all_feature_names)\n",
    "    coef.sort_values(ascending=True).tail(10).plot(kind='barh', ax=ax, color='coral')\n",
    "    ax.set_title(f'{best_model_name}\\n|Coefficient| — Feature Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\n=== {best_model_name} — Classification Report ===')\n",
    "print(classification_report(y_test, y_pred_best, target_names=['No Churn', 'Churn']))"
   ],
   "id": "cell-evaluation"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Deployment Simulation\n",
    "\n",
    "Mensimulasikan deployment: menyimpan model, memuat kembali, dan membuat prediksi pada data baru."
   ],
   "id": "cell-md-6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Save model and preprocessor\n",
    "model_artifacts = {\n",
    "    'model': best_model,\n",
    "    'preprocessor': preprocessor,\n",
    "    'feature_cols': feature_cols,\n",
    "    'model_name': best_model_name\n",
    "}\n",
    "joblib.dump(model_artifacts, 'churn_model.pkl')\n",
    "file_size = os.path.getsize('churn_model.pkl') / 1024\n",
    "print(f'Model saved to churn_model.pkl ({file_size:.1f} KB)')\n",
    "\n",
    "# Load model back\n",
    "loaded = joblib.load('churn_model.pkl')\n",
    "loaded_model = loaded['model']\n",
    "loaded_preprocessor = loaded['preprocessor']\n",
    "print(f'Model loaded: {loaded[\"model_name\"]}')\n",
    "\n",
    "# Simulate new customer predictions\n",
    "new_customers = pd.DataFrame([\n",
    "    {'tenure': 2, 'contract_type': 'Month-to-Month', 'payment_method': 'Electronic Check',\n",
    "     'num_services': 2, 'monthly_charges': 65.0, 'total_charges': 130.0, 'customer_service_calls': 5},\n",
    "    {'tenure': 36, 'contract_type': 'Two Year', 'payment_method': 'Credit Card',\n",
    "     'num_services': 5, 'monthly_charges': 85.0, 'total_charges': 3060.0, 'customer_service_calls': 0},\n",
    "    {'tenure': 12, 'contract_type': 'One Year', 'payment_method': 'Bank Transfer',\n",
    "     'num_services': 3, 'monthly_charges': 55.0, 'total_charges': 660.0, 'customer_service_calls': 2},\n",
    "    {'tenure': 1, 'contract_type': 'Month-to-Month', 'payment_method': 'Mailed Check',\n",
    "     'num_services': 1, 'monthly_charges': 25.0, 'total_charges': 25.0, 'customer_service_calls': 4},\n",
    "])\n",
    "\n",
    "X_new = loaded_preprocessor.transform(new_customers)\n",
    "predictions = loaded_model.predict(X_new)\n",
    "probabilities = loaded_model.predict_proba(X_new)[:, 1]\n",
    "\n",
    "print('\\n=== New Customer Predictions ===')\n",
    "print(f'{\"Customer\":<10} {\"Churn Prob\":>12} {\"Prediction\":>12} {\"Risk Level\":>12}')\n",
    "print('-' * 50)\n",
    "for i, (pred, prob) in enumerate(zip(predictions, probabilities)):\n",
    "    risk = 'HIGH' if prob > 0.7 else ('MEDIUM' if prob > 0.4 else 'LOW')\n",
    "    print(f'Customer {i+1:<2} {prob:>12.3f} {\"Churn\" if pred else \"No Churn\":>12} {risk:>12}')\n",
    "\n",
    "os.remove('churn_model.pkl')\n",
    "print('\\nCleanup: churn_model.pkl removed.')"
   ],
   "id": "cell-deployment"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Business Insights & Rekomendasi\n",
    "\n",
    "Menerjemahkan temuan model menjadi rekomendasi bisnis yang actionable."
   ],
   "id": "cell-md-7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantify business impact\n",
    "n_test = len(y_test)\n",
    "actual_churners = y_test.sum()\n",
    "detected_churners = ((y_pred_best == 1) & (y_test == 1)).sum()  # True Positives\n",
    "recall_val = recall_score(y_test, y_pred_best)\n",
    "\n",
    "REVENUE_PER_CUSTOMER = 2_400_000  # Rp per year\n",
    "INTERVENTION_COST    = 200_000    # Rp per customer (retention offer)\n",
    "RETENTION_RATE       = 0.35       # 35% of identified at-risk customers retained\n",
    "\n",
    "retained_customers = int(detected_churners * RETENTION_RATE)\n",
    "revenue_saved  = retained_customers * REVENUE_PER_CUSTOMER\n",
    "intervention_cost = detected_churners * INTERVENTION_COST\n",
    "net_benefit = revenue_saved - intervention_cost\n",
    "\n",
    "insights = f\"\"\"\n",
    "╔═══════════════════════════════════════════════════════════════════╗\n",
    "║               BUSINESS INSIGHTS & REKOMENDASI                    ║\n",
    "╠═══════════════════════════════════════════════════════════════════╣\n",
    "║                                                                   ║\n",
    "║  MODEL PERFORMANCE (Test Set: {n_test} customers):                ║\n",
    "║  - Actual churners:     {actual_churners:>4}                               ║\n",
    "║  - Detected by model:   {detected_churners:>4} (Recall: {recall_val:.1%})                ║\n",
    "║  - Missed churners:     {actual_churners - detected_churners:>4}                               ║\n",
    "║                                                                   ║\n",
    "║  PERKIRAAN DAMPAK BISNIS (scaled to 1,000 pelanggan):             ║\n",
    "║  - Pelanggan teridentifikasi berisiko: {detected_churners:>4}                  ║\n",
    "║  - Estimasi berhasil dipertahankan:   {retained_customers:>4} (35% retention)   ║\n",
    "║  - Revenue diselamatkan: Rp {revenue_saved:>15,}          ║\n",
    "║  - Biaya intervensi:     Rp {intervention_cost:>15,}          ║\n",
    "║  - Net benefit:          Rp {net_benefit:>15,}          ║\n",
    "║                                                                   ║\n",
    "║  KEY INSIGHTS:                                                    ║\n",
    "║  1. Pelanggan Month-to-Month memiliki risiko churn tertinggi      ║\n",
    "║     → Prioritaskan upsell ke One Year / Two Year contract         ║\n",
    "║  2. Pelanggan baru (tenure < 6 bulan) paling rentan churn         ║\n",
    "║     → Intensifkan onboarding program di 90 hari pertama           ║\n",
    "║  3. Customer service calls > 3 = sinyal kuat churn                ║\n",
    "║     → Flag akun dan eskalasi ke retention specialist              ║\n",
    "║  4. Electronic Check payment = korelasi positif dengan churn      ║\n",
    "║     → Tawarkan insentif beralih ke autopay (bank transfer/CC)     ║\n",
    "╚═══════════════════════════════════════════════════════════════════╝\n",
    "\"\"\"\n",
    "print(insights)"
   ],
   "id": "cell-insights"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tugas Praktikum\n",
    "\n",
    "1. **Tugas 1 — Feature Engineering**: Buat setidaknya 3 fitur baru dari dataset yang ada:\n",
    "   - `avg_monthly_charge` = total_charges / tenure\n",
    "   - `service_density` = num_services / tenure\n",
    "   - `high_caller` = 1 jika customer_service_calls > 3, else 0\n",
    "   \n",
    "   Latih ulang semua model dan bandingkan apakah fitur baru meningkatkan performa.\n",
    "\n",
    "2. **Tugas 2 — Handling Class Imbalance**: Jika churn rate rendah (< 20%), model bisa\n",
    "   bias terhadap kelas mayoritas. Implementasikan:\n",
    "   - **SMOTE** (oversampling minority class menggunakan `imblearn`)\n",
    "   - **class_weight='balanced'** pada Logistic Regression dan Random Forest\n",
    "   \n",
    "   Bandingkan Recall dan F1-score sebelum dan sesudah.\n",
    "\n",
    "3. **Tugas 3 — Hyperparameter Tuning**: Gunakan `GridSearchCV` untuk tuning\n",
    "   Random Forest dengan parameter: `n_estimators` ∈ {50,100,200},\n",
    "   `max_depth` ∈ {5,8,10,None}, `min_samples_split` ∈ {2,5,10}.\n",
    "   Gunakan `scoring='recall'` (karena recall lebih penting untuk churn detection).\n",
    "\n",
    "4. **Tugas 4 — Model Interpretability**: Gunakan library **SHAP** untuk:\n",
    "   - Plot SHAP summary plot (fitur mana paling berpengaruh global)\n",
    "   - Plot SHAP waterfall untuk 3 pelanggan individual (1 high-risk, 1 medium-risk, 1 low-risk)\n",
    "   - Interpretasikan mengapa model memprediksi churn untuk setiap pelanggan"
   ],
   "id": "cell-md-tugas"
  }
 ]
}
